import numpy as na
import math
from optparse import OptionParser
from plot_entropy import calculate_confusion_matrix
from g3.state import state_type_from_name
from g3.evaluator.evaluateCorpus import ResultsFile
from g3.inference.entropy_metrics import Metric
from esdcs.esdcIo import annotationIo
from spatial_features.groundings import PhysicalObject
from g3.evaluator.gui import resultsEntry
from g3.inference.entropy_metrics import estimate_binding_probability, compute_entropy_from_distribution, make_object_id_to_results, compute_normalizer, compute_entropy_metric2

import logging


class NodeResult:
    def __init__(self, i, ggg, node, end_ggg,
                 results=None, annotation=None, entropy_metric="metric1",
                 verbose=False,
                 question_type='targeted'):
        self.id = i
        self.ggg = ggg
        self.end_ggg = end_ggg
        self.node = node
        top_factors = self.ggg.factors_for_node(self.node)
        if annotation is not None:
            log = logging.getLogger(annotation.id)
        else:
            log = logging.getLogger()


        # Unfortunately, we currently need to use different methods to detect original command nodes for yes/no and targeted questions.
        if question_type in ['targeted', 'reset']:
            esdc = self.ggg.node_to_top_esdc(node)
            self.node_esdc = esdc
            if esdc is None:
                self.node_esdc = self.ggg.factor_to_esdc(top_factors[0])
                self.is_original_command = False
            else:
                if annotation is not None and verbose:
                    log.debug("contains %s" % annotation.esdcs.contains(esdc))
                    log.debug("contains %s" % annotation.esdcs.contains(ggg.esdcs))
                    log.debug("contains %s" % ggg.esdcs.contains(esdc))
                    log.debug("node id %s" % node.id in ggg.esdc_to_node_id.values())
                if (annotation is not None and
                    annotation.esdcs.contains(esdc) and
                    annotation.esdcs.contains(ggg.esdcs) and
                    ggg.esdcs.contains(esdc) and
                    node.id in ggg.esdc_to_node_id.values()):
                    self.is_original_command = True
                else:
                    self.is_original_command = False
        elif question_type == 'yn':
            esdcs = [self.ggg.factor_to_esdc(f) for f in top_factors]
            self.is_original_command = False
            self.node_esdc = self.ggg.node_to_top_esdc(self.node)
            if node.is_bound:
                assert len(top_factors) == 1, "Bound node should only have one connected factor"
                assert 'BOUND' in top_factors[0].type, "Bound node should be connected to a bound factor"
                self.node_esdc = self.ggg.factor_to_esdc(top_factors[0])
            else:
                for e in esdcs:
                    if any(e.is_same_constituent(orig_esdc) for orig_esdc in annotation.flattenedEsdcs):
                        self.is_original_command = True
                        self.node_esdc = e
                        break
        elif question_type == "None":
            self.is_original_command = True
            esdc = self.ggg.node_to_top_esdc(node)
            self.node_esdc = esdc
        else:
            raise ValueError("only targeted, reset, and yn question supported now: %s" % question_type)

        if results == None:
            self.results = []
            self.best_result = None
        else:
            self.results = results
            self.best_result = self.results[0]

        self.annotation = annotation
        if self.annotation != None:
            self.annotation_id = self.annotation.id
            try:
                self.labeled_evidences = [annotation.getGroundings(self.node_esdc)]
            except KeyError:
                self.labeled_evidences = [annotation.getGroundings(e) for e in annotation.flattenedEsdcs if e.is_same_constituent(self.node_esdc)]
        else:
            self.annotation_id = None
            self.labeled_evidences = [None]
        self.best_node_cost = end_ggg.cost_for_node(node)
        self.best_node_prob = math.exp(-self.best_node_cost)
        self.best_cost = end_ggg.cost()
        self.best_prob = math.exp(-self.best_cost)

        self.inferred_evidences = end_ggg.evidence_for_node(node)
        if len(self.inferred_evidences) > 0:
            self.inferred_pobj = self.inferred_evidences[0]
        else:
            self.inferred_pobj = None

        # Check the inferred object against the list of labeled evidences. In order to allow the comparison of ESDCs generated by different parsing systems, we needed a more general way to test for equivalence between ESDCs. ExtendedSdc.is_same_constituent will check whether two ESDCs have the same entireText and range, meaning that they represent the same part of the same sentence. Thus, in order to check the correctness of our inferred evicence, we will compare the inferred object to the labeled object from ALL ESDCs in the annotation which pass node_esdc.is_same_constituent. We state that an inferred object is correct if its ID matches the ID of ANY of the is_same_constituent objects in the annotation.
        potential_labeled_evidences = [l for l in self.labeled_evidences if l is not None and len(l) == 1 and isinstance(l[0], PhysicalObject)]
        if len(potential_labeled_evidences) == 0:
            self.is_null_node = True
            self.labeled_pobj = None
            self.correct = False
        else:
            self.is_null_node = False
            if self.inferred_pobj:
                matching_labeled_evicences = [l for l in potential_labeled_evidences if l[0].id == self.inferred_pobj.id]
                if len(matching_labeled_evicences) == 0:
                    self.correct = False
                    self.labeled_pobj = potential_labeled_evidences[0][0]
                else:
                    self.correct = True
                    self.labeled_pobj = matching_labeled_evicences[0][0]
            else:
                self.correct = False

        if self.inferred_pobj:
            self.inferred_tags = ", ".join(self.inferred_pobj.tags)
        else:
            self.inferred_tags = ""

        if self.labeled_pobj:
            self.labeled_tags = ", ".join(self.labeled_pobj.tags)
        else:
            self.labeled_tags = ""

        if self.node_esdc != None:
            self.text = str(self.node_esdc.text)
            self.entire_text = str(self.node_esdc.entireText)
        else:
            self.text = ""
            self.entire_text = ""

        self.entropy_metric_type = entropy_metric
        if self.node.is_bound:
            self.entropy = 0
        elif entropy_metric != None and len(self.results) != 0:
            self.entropy_metric = Metric.from_name(entropy_metric)
            self.entropy = self.entropy_metric.entropy_for_node_result(self)
        else:
            self.entropy = None


        self.end_gggs = [nr.end_ggg for nr in self.results]
        if len(self.results) != 0:
            self.compute_object_entropies()

    def compute_object_entropies(self):
        obj_id_to_results = make_object_id_to_results(self.end_gggs, self.node)
        normalizer = compute_normalizer(self.end_gggs)
        event_node = self.ggg.top_event_node
        self.object_id_to_probability = {}
        self.object_id_to_yn_entropy = {}
        self.object_id_to_yn_event_entropy = {}
        for oid, end_gggs in obj_id_to_results.iteritems():
            self.object_id_to_probability[oid] = estimate_binding_probability(oid, end_gggs, normalizer)
        p_normalizer = sum(self.object_id_to_probability.values())
        for oid, prob in self.object_id_to_probability.iteritems():
            self.object_id_to_probability[oid] = float(prob) / p_normalizer

        for oid, prob in self.object_id_to_probability.iteritems():
            p_yes = prob
            p_no = 1 - prob
            self.object_id_to_yn_entropy[oid] = compute_entropy_from_distribution([p_yes, p_no])
            if not self.node.is_event:
                yes_gggs = obj_id_to_results[oid]
                no_gggs = [ggg for ggg in self.end_gggs if ggg not in yes_gggs]
                if p_yes > 0:
                    yes_event_entropy = compute_entropy_metric2(yes_gggs, event_node)
                else:
                    yes_event_entropy = 0
                if p_no > 0:
                    no_event_entropy = compute_entropy_metric2(no_gggs, event_node)
                else:
                    no_event_entropy = 0
                self.object_id_to_yn_event_entropy[oid] = p_yes * yes_event_entropy + p_no * no_event_entropy

    # def predict_yn_event_entropy(self):
    #     object_id_to_yn_event_entropy = {}
    #     event_node = self.ggg.top_event_node
    #     for oid in self.object_id_to_yn_entropy.keys():
    #         object_id_to_yn_event_entropy[oid] = compute_expected_event_entropy(self.end_gggs, event_node, self.node, oid)
    #     return object_id_to_yn_event_entropy



def compute_node_results(result_entries, 
                         entropy_metric="metric1",
                         include_events=False,
                         include_objects=True,
                         verbose=False,
                         question_type='targeted'):
    result = []
    num_nodes = 0
    num_evaluated = 0

    # print "number of result entries:", len(result_entries)

    for i, entry in enumerate(result_entries):

        # print "entry ID", entry.annotation.id
        # print "annotationId", annotationId

        original_annotation = entry.annotation
        log = logging.getLogger(original_annotation.id)


        for ggg in entry.start_gggs:
            log.debug("New GGG")
            log.debug("Text: %s" % ggg.esdcs.text)
            assert include_events or include_objects, "Must include either event or object nodes (or both)"
            nodes = []
            if include_objects:
                nodes += ggg.lexicalized_object_nodes
            if include_events:
                nodes += [ggg.top_event_node]
            for node in nodes:
                num_nodes += 1
                # esdc = ggg.node_to_top_esdc(node)

                # if (commands_corpus != None and
                #     original_annotation.esdcs.contains(esdc) and
                #     original_annotation.esdcs.contains(ggg.esdcs) and
                #     ggg.esdcs.contains(esdc) and
                #     node.id in ggg.esdc_to_node_id.values()):
                #     is_original_command = True
                # else:
                #     is_original_command = False
                num_evaluated += 1
                node_result = NodeResult(i, ggg, node, entry.end_ggg,
                                         # is_original_command,
                                         entry.results, original_annotation,
                                         entropy_metric=entropy_metric,
                                         verbose=verbose,
                                         question_type=question_type)
                if not include_events:
                    log.debug('%s %s' % (node_result.node_esdc.text, node_result.node_esdc.range))
                    log.debug(node_result.ggg.entireText)
                    log.debug("Original? %s" % node_result.is_original_command)

                result.append(node_result)
    return result


def final_event_entropies(results_entries, commands_corpus, question_type='targeted'):
    node_results = compute_node_results(results_entries, commands_corpus,
                                        include_events=True,
                                        include_objects=False,
                                        entropy_metric='metric2',
                                        verbose=False,
                                        question_type=question_type)
    event_node_results = [nr for nr in node_results if nr.node.is_event]
    return [nr.entropy for nr in event_node_results]


def node_bindings_cm_from_results(entries, state_type, commands_corpus, question_type='targeted'):
    """
    Generate a confusion matrix based on the number of correctly
    grounded nodes in the specified results file.
    """

    node_entries = compute_node_results(entries, commands_corpus,
                                        include_events=False,
                                        verbose=True,
                                        question_type=question_type)
    cm = calculate_confusion_matrix(node_entries)
    return cm


def main():
    parser = OptionParser()
    parser.add_option("--result-fname", dest="result_fname")
    parser.add_option("--state-type", dest="state_type")

    parser.add_option("--original-commands", dest="corpus_fname", default=None, action='append')
    parser.add_option("--question_type", dest="question_type", default='targeted')

    (options, args) = parser.parse_args()
    evaluate_nodes(options)


def evaluate_nodes(options):
    state_type = state_type_from_name(options.state_type)
    results = ResultsFile(options.result_fname)
    entries = resultsEntry.Entry.entries_from_results_file(results)
    commands_fname = options.corpus_fname
    if commands_fname != None:
        commands_corpus = annotationIo.load_all(commands_fname)
    else:
        commands_corpus = None
    log = logging.getLogger()

    cm = node_bindings_cm_from_results(entries, state_type, commands_corpus,
                                       question_type=options.question_type)
    cm.print_all()

    event_entropies = final_event_entropies(entries, commands_corpus,
                                        question_type=options.question_type)
    log.info('Event entropy mean: {:.3g} +- {:.3g}'.format(na.mean(event_entropies), na.std(event_entropies)))
    log.debug("Length: %d" % len(event_entropies))
    return cm, event_entropies

if __name__ == "__main__":
    main()
